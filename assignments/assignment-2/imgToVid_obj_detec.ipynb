{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa374c54",
      "metadata": {
        "id": "fa374c54"
      },
      "source": [
        "# Car Parts Detection - Colab \n",
        "Run this notebook in Google Colab with GPU runtime enabled.\n",
        "\n",
        "**Setup:** Runtime â†’ Change runtime type â†’ GPU â†’ Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d102cbce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d102cbce",
        "outputId": "7debfe37-3cd3-40bc-bb7c-1e27f083fafa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "%pip install ultralytics yt-dlp pyarrow -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "52cfac3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52cfac3d",
        "outputId": "acdf278e-9816-4a8f-d1fd-40bc71ecfdf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Verify GPU is available\n",
        "import torch\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e462a5",
      "metadata": {
        "id": "43e462a5"
      },
      "source": [
        "## 1. Download and Extract Video Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4031682",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4031682",
        "outputId": "e0ed115e-693a-4308-e2c6-d47b4305ee81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=YcvECxtXoxQ\n",
            "[youtube] YcvECxtXoxQ: Downloading webpage\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "[youtube] YcvECxtXoxQ: Downloading android vr player API JSON\n",
            "[info] YcvECxtXoxQ: Downloading 1 format(s): 401+140\n",
            "[download] Destination: input_video.f401.mp4\n",
            "\u001b[K[download] 100% of    4.26GiB in \u001b[1;37m00:02:22\u001b[0m at \u001b[0;32m30.68MiB/s\u001b[0m\n",
            "[download] Destination: input_video.f140.m4a\n",
            "\u001b[K[download] 100% of   43.12MiB in \u001b[1;37m00:00:02\u001b[0m at \u001b[0;32m21.30MiB/s\u001b[0m\n",
            "[Merger] Merging formats into \"input_video.mp4\"\n",
            "Deleting original file input_video.f140.m4a (pass -k to keep)\n",
            "Deleting original file input_video.f401.mp4 (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "# Download video\n",
        "!yt-dlp -f \"bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]\" \\\n",
        "  -o \"input_video.mp4\" \\\n",
        "  \"https://www.youtube.com/watch?v=YcvECxtXoxQ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4112d80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4112d80",
        "outputId": "d02fa1a9-409f-4937-8928-dee73e47958f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[1;36m[libdav1d @ 0x5b01df75f480] \u001b[0mlibdav1d 0.9.2\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomav01iso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:46:33.85, start: 0.000000, bitrate: 13236 kb/s\n",
            "  Stream #0:0(und): Video: av1 (Main) (av01 / 0x31307661), yuv420p(tv, bt709), 3840x2160 [SAR 1:1 DAR 16:9], 13096 kb/s, 59.94 fps, 59.94 tbr, 60k tbn, 60k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Output #0, mp4, to 'clip_120_165.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomav01iso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: av1 (Main) (av01 / 0x31307661), yuv420p(tv, bt709), 3840x2160 [SAR 1:1 DAR 16:9], q=2-31, 13096 kb/s, 59.94 fps, 59.94 tbr, 60k tbn, 60k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #0:1 -> #0:1 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame=    0 fps=0.0 q=-1.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \rframe= 2851 fps=0.0 q=-1.0 Lsize=  134025kB time=00:00:44.99 bitrate=24399.6kbits/s speed= 260x    \n",
            "video:133227kB audio:743kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.041352%\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[1;36m[libdav1d @ 0x58533ada2440] \u001b[0mlibdav1d 0.9.2\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'clip_120_165.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomav01iso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:45.02, start: 0.000000, bitrate: 24390 kb/s\n",
            "  Stream #0:0(und): Video: av1 (Main) (av01 / 0x31307661), yuv420p(tv, bt709), 3840x2160 [SAR 1:1 DAR 16:9], 24245 kb/s, 59.94 fps, 59.94 tbr, 60k tbn, 60k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 135 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "\u001b[1;36m[libdav1d @ 0x58533adcbbc0] \u001b[0mlibdav1d 0.9.2\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (av1 (libdav1d) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x58533ae06440] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to 'frames/frame_%04d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomav01iso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: mjpeg, yuvj420p(pc, bt709, progressive), 3840x2160 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 1 fps, 1 tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
            "frame=   47 fps=0.4 q=24.8 Lsize=N/A time=00:00:47.00 bitrate=N/A dup=0 drop=1 speed=0.358x    \n",
            "video:9646kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Extracted 47 frames\n"
          ]
        }
      ],
      "source": [
        "# Extract 45-second clip starting at 2:00\n",
        "!ffmpeg -ss 00:02:00 -i input_video.mp4 -t 45 -c copy clip_120_165.mp4 -y\n",
        "\n",
        "# Extract frames (1 per second)\n",
        "!mkdir -p frames\n",
        "!ffmpeg -i clip_120_165.mp4 -vf \"fps=1\" frames/frame_%04d.jpg -y\n",
        "\n",
        "# Verify\n",
        "import os\n",
        "print(f\"Extracted {len([f for f in os.listdir('frames') if f.endswith('.jpg')])} frames\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "474e30cc",
      "metadata": {
        "id": "474e30cc"
      },
      "source": [
        "## 2. Train Car Parts Segmentation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa514ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fa514ea",
        "outputId": "f3d5b4d0-1a07-49b7-c414-4a24b000bde2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Training car parts segmentation model...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n-seg.pt to 'yolov8n-seg.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.7MB 77.8MB/s 0.1s\n",
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=carparts-seg.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "WARNING âš ï¸ Dataset 'carparts-seg.yaml' images not found, missing path '/content/datasets/carparts-seg/images/val'\n",
            "\u001b[KDownloading https://ultralytics.com/assets/carparts-seg.zip to '/content/datasets/carparts-seg.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 133.1MB 166.4MB/s 0.8s\n",
            "\u001b[KUnzipping /content/datasets/carparts-seg.zip to /content/datasets/carparts-seg...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7675/7675 4.4Kfiles/s 1.7s\n",
            "Dataset download success âœ… (2.9s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 35.6MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=23\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1008565  ultralytics.nn.modules.head.Segment          [23, 32, 64, 16, None, [64, 128, 256]]\n",
            "YOLOv8n-seg summary: 152 layers, 3,268,101 parameters, 3,268,085 gradients, 11.5 GFLOPs\n",
            "\n",
            "Transferred 381/417 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 154.9MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1131.0Â±415.5 MB/s, size: 35.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/carparts-seg/labels/train... 3156 images, 116 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3156/3156 1.6Kit/s 1.9s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/carparts-seg/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 986.0Â±658.0 MB/s, size: 37.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/carparts-seg/labels/val... 401 images, 12 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 401/401 824.3it/s 0.5s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/carparts-seg/labels/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00037, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "Plotting labels to /content/runs/segment/train/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/segment/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       1/50      2.84G      1.303      2.686      3.628      1.419          0         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.1it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.5s\n",
            "                   all        401       2042      0.353      0.274      0.182      0.129      0.405      0.256      0.182       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       2/50      3.48G      1.113      2.021      2.237      1.249          0         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.6it/s 7.9s\n",
            "                   all        401       2042      0.413      0.499      0.344      0.253      0.413      0.497      0.343      0.238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       3/50      3.49G      1.015      1.818      1.766      1.173          0         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.3s\n",
            "                   all        401       2042       0.48      0.459      0.394      0.289       0.49      0.463      0.395      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       4/50       3.5G     0.9655      1.712      1.581      1.134          0         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.6s\n",
            "                   all        401       2042      0.395      0.633      0.462      0.351      0.442      0.553      0.468      0.332\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       5/50      3.53G     0.9298      1.639      1.439      1.112          0         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.5s\n",
            "                   all        401       2042      0.456      0.684       0.55      0.415       0.46      0.687      0.553      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       6/50      3.54G     0.8976      1.562      1.307      1.088          0         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.7it/s 7.6s\n",
            "                   all        401       2042      0.525      0.618      0.577       0.45      0.523      0.618       0.58       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       7/50      3.57G      0.872       1.51      1.245      1.069          0         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.3s\n",
            "                   all        401       2042      0.525      0.646       0.58       0.45      0.527      0.643      0.582      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       8/50      3.57G     0.8567      1.482      1.197      1.062          0         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.4s\n",
            "                   all        401       2042       0.48      0.695      0.559      0.436      0.486      0.695      0.564      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       9/50       3.6G     0.8396      1.447      1.145      1.056          0         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.8s\n",
            "                   all        401       2042      0.511      0.666      0.575      0.442      0.512      0.666      0.572      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      10/50      3.61G     0.8243      1.416      1.102      1.046          0         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.4s\n",
            "                   all        401       2042      0.572      0.663      0.632      0.502      0.573      0.662      0.639      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      11/50      3.64G     0.8178      1.397      1.079      1.042          0         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.3s\n",
            "                   all        401       2042      0.531      0.729      0.612      0.494      0.539      0.733      0.628      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      12/50      3.65G     0.8075      1.371      1.032      1.035          0         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.4it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 6.0s\n",
            "                   all        401       2042      0.554      0.731      0.637      0.517      0.546      0.741      0.645      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      13/50      3.68G     0.8018      1.354      1.021       1.03          0         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 7.0s\n",
            "                   all        401       2042      0.584      0.752      0.643      0.513      0.576       0.75      0.646      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      14/50      3.69G     0.7921      1.345     0.9967      1.028          0         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 6.0s\n",
            "                   all        401       2042      0.524       0.72      0.602      0.479      0.524      0.721      0.601      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      15/50      3.71G     0.7802      1.319     0.9759      1.018          0         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.9s\n",
            "                   all        401       2042      0.562      0.764      0.648      0.518      0.561      0.758      0.652      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      16/50      3.72G     0.7721      1.306     0.9436      1.011          0         56        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.9s\n",
            "                   all        401       2042      0.573      0.756      0.661      0.538      0.576      0.759      0.668      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      17/50      3.75G     0.7609      1.288     0.9275      1.013          0         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 6.0s\n",
            "                   all        401       2042       0.54      0.751      0.654      0.535      0.542      0.765      0.663      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      18/50      3.76G     0.7537      1.269     0.8952      1.004          0         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.8s\n",
            "                   all        401       2042      0.556      0.786      0.663      0.544       0.56       0.79      0.672      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      19/50      3.79G     0.7518      1.266     0.8974      1.005          0         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.1s\n",
            "                   all        401       2042      0.529      0.744      0.652      0.534      0.531      0.746       0.66      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      20/50       3.8G     0.7413       1.25     0.8752      1.002          0         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.3s\n",
            "                   all        401       2042      0.552      0.758      0.643      0.528      0.554      0.761      0.651      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      21/50      3.83G     0.7331      1.229     0.8677     0.9971          0         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.1s\n",
            "                   all        401       2042      0.582      0.768      0.671       0.55      0.587       0.76      0.676      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      22/50      3.84G     0.7336      1.232     0.8534     0.9936          0         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.1s\n",
            "                   all        401       2042      0.537      0.774      0.618       0.51      0.541      0.784      0.629      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      23/50      3.86G     0.7231       1.21     0.8382     0.9897          0         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.2s\n",
            "                   all        401       2042      0.525      0.725      0.625      0.521      0.528      0.722      0.631      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      24/50      3.87G     0.7198      1.207      0.821     0.9889          0         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.0s\n",
            "                   all        401       2042      0.548      0.813      0.677      0.562      0.549      0.813      0.683      0.548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      25/50       3.9G     0.7159      1.191     0.8181     0.9869          0         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.7s\n",
            "                   all        401       2042       0.57      0.755      0.666      0.547      0.581      0.758      0.676      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      26/50      3.91G     0.7032      1.163     0.7931     0.9794          0         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.2s\n",
            "                   all        401       2042      0.521      0.768      0.632      0.529      0.523      0.772       0.64      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      27/50      3.94G     0.7059      1.167     0.7907     0.9818          0         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 7.0s\n",
            "                   all        401       2042      0.559      0.791      0.676      0.562      0.568      0.801      0.694      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      28/50      3.95G     0.6963      1.153     0.7783     0.9768          0         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.3s\n",
            "                   all        401       2042      0.563      0.805      0.674      0.558      0.579      0.807       0.69      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      29/50      3.97G     0.6941      1.147     0.7752      0.975          0         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.2s\n",
            "                   all        401       2042      0.571       0.79       0.67      0.564      0.577       0.79      0.678      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      30/50      3.98G     0.6908      1.136     0.7681     0.9755          0         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.8s\n",
            "                   all        401       2042      0.558      0.792      0.679      0.568      0.562      0.794      0.687      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      31/50      4.01G      0.687      1.146     0.7602     0.9734          0         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.3s\n",
            "                   all        401       2042      0.581      0.816      0.679      0.571      0.585       0.81      0.687      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      32/50      4.02G     0.6771       1.13     0.7474     0.9711          0         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.8it/s 7.1s\n",
            "                   all        401       2042       0.53      0.736      0.635      0.536      0.534      0.743      0.645      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      33/50      4.05G     0.6787      1.109     0.7333      0.963          0         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.2s\n",
            "                   all        401       2042       0.57      0.767      0.648      0.542      0.572      0.771      0.654      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      34/50      4.06G     0.6798      1.135     0.7432     0.9694          0         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.8s\n",
            "                   all        401       2042      0.576      0.781      0.645      0.543      0.586      0.784      0.664      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      35/50      4.09G     0.6733      1.122     0.7326     0.9665          0         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.1s\n",
            "                   all        401       2042      0.554      0.782      0.646      0.543       0.56      0.795      0.662      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      36/50      4.09G     0.6683      1.103      0.721     0.9649          0         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.5s\n",
            "                   all        401       2042      0.562      0.751      0.654      0.549       0.57      0.762      0.668      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      37/50      4.12G     0.6657      1.097     0.7222      0.963          0         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.9it/s 6.7s\n",
            "                   all        401       2042      0.583      0.761      0.664       0.56      0.591      0.775      0.676      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      38/50      4.14G     0.6637        1.1     0.7143     0.9618          0         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.6s\n",
            "                   all        401       2042        0.6      0.771      0.679      0.571      0.607      0.779      0.695      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      39/50      4.16G     0.6529      1.083     0.6983     0.9576          0         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.5s\n",
            "                   all        401       2042      0.549      0.806      0.632      0.532      0.555       0.81      0.644      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      40/50      4.17G     0.6559       1.08     0.7046     0.9594          0         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.5it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.2s\n",
            "                   all        401       2042      0.603      0.793      0.674      0.565      0.606      0.795       0.68      0.553\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      41/50       4.2G     0.5973     0.9627     0.6288      0.942          0         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.8it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        401       2042      0.564      0.801      0.669      0.566      0.568       0.78      0.682       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      42/50      4.21G     0.5859     0.9297     0.5952     0.9341          0         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.9it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.4it/s 5.5s\n",
            "                   all        401       2042      0.567       0.81      0.677       0.57      0.572       0.81      0.689      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      43/50      4.24G     0.5792     0.9278     0.5821     0.9314          0         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.9it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.5it/s 5.3s\n",
            "                   all        401       2042      0.604      0.788      0.692      0.586      0.614      0.797       0.71      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      44/50      4.25G     0.5726     0.9102     0.5671     0.9247          0         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 3.0it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        401       2042      0.568        0.8       0.67      0.567      0.582       0.78      0.686      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      45/50      4.27G     0.5672      0.904     0.5631     0.9238          0         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.9it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.5it/s 5.1s\n",
            "                   all        401       2042      0.585      0.768      0.673      0.571      0.594      0.778      0.689      0.555\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      46/50      4.28G     0.5655      0.899     0.5558     0.9204          0         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 3.0it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.1s\n",
            "                   all        401       2042       0.57      0.762      0.659      0.561      0.577      0.771      0.672      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      47/50      4.31G     0.5613     0.8916     0.5519     0.9213          0         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.9it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.6it/s 5.1s\n",
            "                   all        401       2042      0.575      0.762      0.664      0.563      0.584      0.776      0.679      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      48/50      4.32G     0.5539     0.8917     0.5495     0.9155          0         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.9it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 6.0s\n",
            "                   all        401       2042      0.572       0.76      0.657      0.559      0.582      0.772      0.673      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      49/50      4.34G     0.5543     0.8906     0.5489     0.9159          0         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.9it/s 1:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.6it/s 5.1s\n",
            "                   all        401       2042      0.582      0.773       0.66      0.564      0.589      0.774      0.676      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      50/50      4.36G     0.5469      0.881     0.5361     0.9151          0         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 198/198 2.9it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.1s\n",
            "                   all        401       2042      0.595      0.765      0.671      0.573      0.606      0.772      0.688      0.555\n",
            "\n",
            "50 epochs completed in 1.179 hours.\n",
            "Optimizer stripped from /content/runs/segment/train/weights/last.pt, 6.8MB\n",
            "Optimizer stripped from /content/runs/segment/train/weights/best.pt, 6.8MB\n",
            "\n",
            "Validating /content/runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
            "YOLOv8n-seg summary (fused): 86 layers, 3,262,549 parameters, 0 gradients, 11.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.3it/s 10.1s\n",
            "                   all        401       2042      0.607      0.788      0.693      0.586      0.616      0.797       0.71      0.572\n",
            "           back_bumper         94         94      0.866      0.936      0.925      0.772      0.867      0.936      0.925      0.747\n",
            "             back_door        158        159      0.858      0.871      0.938      0.842      0.857       0.87      0.938      0.826\n",
            "            back_glass        114        115      0.878       0.93      0.957      0.838      0.879       0.93      0.957      0.809\n",
            "        back_left_door         15         15      0.503          1      0.744      0.682      0.504          1      0.744      0.643\n",
            "       back_left_light         19         19      0.576      0.632      0.575      0.422      0.579      0.632      0.558      0.401\n",
            "            back_light        161        226      0.887      0.837      0.879      0.663      0.892      0.841       0.87       0.63\n",
            "       back_right_door         12         12      0.378       0.75      0.451      0.387      0.379       0.75      0.451      0.376\n",
            "      back_right_light         13         13      0.575      0.769      0.659       0.56      0.583      0.769      0.659      0.504\n",
            "          front_bumper        208        208      0.926      0.976      0.973      0.893      0.927      0.976      0.973      0.892\n",
            "            front_door        167        167      0.876      0.929      0.933      0.846      0.876      0.929      0.933      0.833\n",
            "           front_glass        214        214      0.929       0.98      0.978      0.908      0.929       0.98      0.978      0.916\n",
            "       front_left_door         15         15      0.405          1      0.635      0.602      0.407          1      0.635      0.539\n",
            "      front_left_light         30         30      0.387        0.8      0.499      0.378      0.391        0.8      0.499      0.377\n",
            "           front_light        248        373      0.903       0.87      0.899      0.703      0.903      0.869      0.899      0.678\n",
            "      front_right_door         12         12      0.374      0.833      0.417      0.369      0.384      0.833      0.417      0.329\n",
            "     front_right_light         26         26      0.501      0.769      0.665      0.557      0.512      0.769      0.665      0.568\n",
            "                  hood        214        214      0.913      0.977      0.974      0.888      0.913      0.977      0.974      0.897\n",
            "           left_mirror         31         31      0.525      0.676      0.554      0.376      0.521      0.668      0.554      0.392\n",
            "                object          1          1          0          0          0          0          0          0          0          0\n",
            "          right_mirror         31         31      0.528       0.71      0.648      0.435      0.533       0.71      0.648      0.456\n",
            "              tailgate          5          5      0.331        0.6      0.548      0.489      0.443        0.8      0.782      0.549\n",
            "                 trunk          9          9      0.406      0.778      0.651      0.585      0.348      0.667      0.611      0.481\n",
            "                 wheel         34         53      0.423      0.491      0.431      0.288      0.538      0.623      0.668       0.31\n",
            "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/segment/train\u001b[0m\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Train model on car parts dataset (with GPU this takes ~15-30 min)\n",
        "weights_path = \"runs/segment/train/weights/best.pt\"\n",
        "if not os.path.exists(weights_path):\n",
        "    print(\"Training car parts segmentation model...\")\n",
        "    base_model = YOLO(\"yolov8n-seg.pt\")\n",
        "    base_model.train(data=\"carparts-seg.yaml\", epochs=50, imgsz=640)\n",
        "    print(\"Training complete!\")\n",
        "else:\n",
        "    print(\"Model already trained, loading weights...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afea35cc",
      "metadata": {
        "id": "afea35cc"
      },
      "source": [
        "## 3. Run Detection on Video Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5be21e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5be21e0",
        "outputId": "66422497-2047-4068-c1b7-cbb62289d2f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/frames/frame_0001.jpg: 384x640 1 back_glass, 2 right_mirrors, 51.8ms\n",
            "Speed: 2.2ms preprocess, 51.8ms inference, 47.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0002.jpg: 384x640 1 back_bumper, 1 back_glass, 1 back_left_light, 1 tailgate, 7.7ms\n",
            "Speed: 2.8ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0003.jpg: 384x640 2 back_glasss, 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0004.jpg: 384x640 1 back_bumper, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0005.jpg: 384x640 1 back_glass, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0006.jpg: 384x640 1 back_glass, 1 hood, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0007.jpg: 384x640 1 back_glass, 1 hood, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0008.jpg: 384x640 1 front_light, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0009.jpg: 384x640 1 back_bumper, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0010.jpg: 384x640 1 back_bumper, 2 tailgates, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0011.jpg: 384x640 1 back_bumper, 3 back_glasss, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0012.jpg: 384x640 2 front_glasss, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0013.jpg: 384x640 (no detections), 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0014.jpg: 384x640 (no detections), 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0015.jpg: 384x640 (no detections), 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0016.jpg: 384x640 1 wheel, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0017.jpg: 384x640 1 tailgate, 1 wheel, 19.0ms\n",
            "Speed: 3.6ms preprocess, 19.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0018.jpg: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0019.jpg: 384x640 1 back_bumper, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0020.jpg: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0021.jpg: 384x640 1 front_glass, 1 front_left_light, 7.4ms\n",
            "Speed: 2.2ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0022.jpg: 384x640 1 back_glass, 1 right_mirror, 1 wheel, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0023.jpg: 384x640 1 back_bumper, 1 back_glass, 1 right_mirror, 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0024.jpg: 384x640 1 back_glass, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0025.jpg: 384x640 1 back_glass, 1 right_mirror, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0026.jpg: 384x640 1 back_bumper, 1 back_glass, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0027.jpg: 384x640 1 back_glass, 1 front_bumper, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0028.jpg: 384x640 1 back_glass, 1 front_bumper, 1 hood, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0029.jpg: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0030.jpg: 384x640 1 back_glass, 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0031.jpg: 384x640 1 front_glass, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0032.jpg: 384x640 1 hood, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0033.jpg: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0034.jpg: 384x640 1 back_bumper, 1 back_glass, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0035.jpg: 384x640 1 back_bumper, 1 back_glass, 1 back_left_light, 1 right_mirror, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0036.jpg: 384x640 1 back_glass, 1 back_left_light, 1 wheel, 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0037.jpg: 384x640 1 back_glass, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0038.jpg: 384x640 1 back_bumper, 1 back_glass, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0039.jpg: 384x640 1 back_glass, 1 right_mirror, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0040.jpg: 384x640 1 back_glass, 7.9ms\n",
            "Speed: 2.8ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0041.jpg: 384x640 2 back_bumpers, 1 back_glass, 1 back_left_light, 1 right_mirror, 1 wheel, 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0042.jpg: 384x640 1 back_bumper, 1 back_glass, 1 right_mirror, 1 wheel, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0043.jpg: 384x640 1 back_glass, 1 right_mirror, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0044.jpg: 384x640 1 back_bumper, 1 back_glass, 1 back_left_light, 7.5ms\n",
            "Speed: 1.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0045.jpg: 384x640 1 back_glass, 1 back_left_light, 1 wheel, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0046.jpg: 384x640 2 back_bumpers, 1 back_glass, 1 back_left_light, 1 right_mirror, 1 wheel, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames/frame_0047.jpg: 384x640 1 back_bumper, 1 back_glass, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Total detections: 92\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from ultralytics import YOLO\n",
        "import os, json\n",
        "\n",
        "# Load trained car parts model\n",
        "model = YOLO(\"runs/segment/train/weights/best.pt\")\n",
        "\n",
        "frames_dir = \"frames\"\n",
        "results_list = []\n",
        "\n",
        "for fname in sorted(os.listdir(frames_dir)):\n",
        "    if not fname.endswith(\".jpg\"):\n",
        "        continue\n",
        "\n",
        "    frame_idx = int(fname.replace(\"frame_\", \"\").replace(\".jpg\", \"\"))\n",
        "    timestamp_sec = 120 + (frame_idx - 1)  # Clip starts at 2:00 (120 sec)\n",
        "\n",
        "    path = os.path.join(frames_dir, fname)\n",
        "    results = model(path)[0]\n",
        "\n",
        "    for box in results.boxes:\n",
        "        results_list.append({\n",
        "            \"video_id\": \"YcvECxtXoxQ\",\n",
        "            \"frame_idx\": frame_idx,\n",
        "            \"timestamp_sec\": timestamp_sec,\n",
        "            \"class_label\": model.names[int(box.cls)],\n",
        "            \"confidence_score\": float(box.conf),\n",
        "            \"x_min\": float(box.xyxy[0][0]),\n",
        "            \"y_min\": float(box.xyxy[0][1]),\n",
        "            \"x_max\": float(box.xyxy[0][2]),\n",
        "            \"y_max\": float(box.xyxy[0][3])\n",
        "        })\n",
        "\n",
        "print(f\"Total detections: {len(results_list)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7531bcc3",
      "metadata": {
        "id": "7531bcc3"
      },
      "source": [
        "## 4. Save Detections to Parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67620af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a67620af",
        "outputId": "e2016b89-b1ee-4bea-ca18-883f956eeaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      video_id  frame_idx  timestamp_sec      class_label  confidence_score  \\\n",
            "0  YcvECxtXoxQ          1            120       back_glass          0.477926   \n",
            "1  YcvECxtXoxQ          1            120     right_mirror          0.251558   \n",
            "2  YcvECxtXoxQ          1            120     right_mirror          0.250252   \n",
            "3  YcvECxtXoxQ          2            121       back_glass          0.727625   \n",
            "4  YcvECxtXoxQ          2            121         tailgate          0.563668   \n",
            "5  YcvECxtXoxQ          2            121      back_bumper          0.410849   \n",
            "6  YcvECxtXoxQ          2            121  back_left_light          0.364683   \n",
            "7  YcvECxtXoxQ          3            122       back_glass          0.273512   \n",
            "8  YcvECxtXoxQ          3            122       back_glass          0.261468   \n",
            "9  YcvECxtXoxQ          4            123      back_bumper          0.253153   \n",
            "\n",
            "         x_min        y_min        x_max        y_max  \n",
            "0     4.049194    91.100807  2189.681396   789.070312  \n",
            "1  1630.784546   969.553894  1793.621704  1147.091064  \n",
            "2  1626.520386   909.701660  1788.607544  1127.106079  \n",
            "3     7.212891    29.714424  2619.140625   654.623779  \n",
            "4  2322.960449  1281.673218  3017.492188  1955.216309  \n",
            "5  1000.445679  1505.119141  3431.407471  2160.000000  \n",
            "6  2447.777832  1311.860596  3026.152832  1605.376953  \n",
            "7     8.236084     9.081207  3373.180664   699.190552  \n",
            "8  3092.770752  1086.423706  3833.990479  1525.683105  \n",
            "9   332.474854  1087.476929  3734.138184  2158.077637  \n",
            "\n",
            "Unique classes detected: ['back_glass' 'right_mirror' 'tailgate' 'back_bumper' 'back_left_light' 'hood' 'front_light' 'front_glass' 'wheel' 'front_left_light' 'front_bumper']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_parquet(\"video_detections.parquet\", index=False)\n",
        "print(df.head(10))\n",
        "print(f\"\\nUnique classes detected: {df['class_label'].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e34e880d",
      "metadata": {
        "id": "e34e880d"
      },
      "source": [
        "## 5. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfe8162",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fcfe8162",
        "outputId": "54fcc3d5-4dbc-4851-de88-2b94c7d7b2e7"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6aba2ee1-8f64-4b73-93aa-ceb38ca244a0\", \"video_detections.parquet\", 9431)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_716724a2-5085-4482-a9f4-c57b053437ab\", \"best.pt\", 6791156)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download parquet file\n",
        "files.download(\"video_detections.parquet\")\n",
        "\n",
        "# Download trained model weights\n",
        "files.download(\"runs/segment/train/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0b39ae8",
      "metadata": {},
      "source": [
        "# Image-to-Video Semantic Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ceb2af48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      video_id  frame_idx  timestamp_sec   class_label  confidence_score  \\\n",
            "0  YcvECxtXoxQ          1            120    back_glass          0.477926   \n",
            "1  YcvECxtXoxQ          1            120  right_mirror          0.251558   \n",
            "2  YcvECxtXoxQ          1            120  right_mirror          0.250252   \n",
            "3  YcvECxtXoxQ          2            121    back_glass          0.727625   \n",
            "4  YcvECxtXoxQ          2            121      tailgate          0.563668   \n",
            "\n",
            "         x_min        y_min        x_max        y_max  \n",
            "0     4.049194    91.100807  2189.681396   789.070312  \n",
            "1  1630.784546   969.553894  1793.621704  1147.091064  \n",
            "2  1626.520386   909.701660  1788.607544  1127.106079  \n",
            "3     7.212891    29.714424  2619.140625   654.623779  \n",
            "4  2322.960449  1281.673218  3017.492188  1955.216309  \n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load detection index\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet(\"video_detections.parquet\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "06c40c4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ready. Classes: ['back_bumper', 'back_door', 'back_glass', 'back_left_door', 'back_left_light', 'back_light', 'back_right_door', 'back_right_light', 'front_bumper', 'front_door', 'front_glass', 'front_left_door', 'front_left_light', 'front_light', 'front_right_door', 'front_right_light', 'hood', 'left_mirror', 'object', 'right_mirror', 'tailgate', 'trunk', 'wheel']\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Load model and define query class detector\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"best.pt\")  # trained car parts model (local)\n",
        "\n",
        "def get_query_classes(image_path, confidence_threshold=0.5):\n",
        "    \"\"\"Run detector on a query image, return detected class names above threshold.\"\"\"\n",
        "    results = model(image_path, verbose=False)[0]\n",
        "    detected = []\n",
        "    for box in results.boxes:\n",
        "        if float(box.conf) >= confidence_threshold:\n",
        "            detected.append(model.names[int(box.cls)])\n",
        "    return list(set(detected))\n",
        "\n",
        "print(\"Model ready. Classes:\", list(model.names.values()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dc2a1261",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3 & 4: Merge detections into contiguous time intervals\n",
        "def merge_intervals(timestamps, gap_threshold=10):\n",
        "    \"\"\"Merge timestamps that are close together into contiguous intervals.\"\"\"\n",
        "    if len(timestamps) == 0:\n",
        "        return []\n",
        "    timestamps = sorted(timestamps)\n",
        "    intervals = []\n",
        "    start = timestamps[0]\n",
        "    end = timestamps[0]\n",
        "    for t in timestamps[1:]:\n",
        "        if t - end <= gap_threshold:\n",
        "            end = t\n",
        "        else:\n",
        "            intervals.append((start, end))\n",
        "            start = t\n",
        "            end = t\n",
        "    intervals.append((start, end))\n",
        "    return intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a84af56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m  WARNING: The script markdown-it is installed in '/home/vscode/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/home/vscode/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script typer is installed in '/home/vscode/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts hf and tiny-agents are installed in '/home/vscode/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/home/vscode/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:00<00:00, 65.39 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total retrieval results: 72\n",
            "  query_timestamp  start_timestamp  end_timestamp  \\\n",
            "0           00:00              120            120   \n",
            "1           00:00              131            165   \n",
            "2           00:05              135            165   \n",
            "3           00:10              135            165   \n",
            "4           00:15              120            165   \n",
            "\n",
            "                                         class_label  \\\n",
            "0  front_right_door, wheel, front_glass, front_le...   \n",
            "1  front_right_door, wheel, front_glass, front_le...   \n",
            "2  front_bumper, wheel, front_left_door, back_lef...   \n",
            "3  front_left_door, back_left_door, front_bumper,...   \n",
            "4  front_bumper, wheel, front_glass, hood, front_...   \n",
            "\n",
            "   number_of_supporting_detections  \\\n",
            "0                                2   \n",
            "1                               21   \n",
            "2                               10   \n",
            "3                               10   \n",
            "4                               29   \n",
            "\n",
            "                                          verify_url  \n",
            "0  https://www.youtube.com/embed/YcvECxtXoxQ?star...  \n",
            "1  https://www.youtube.com/embed/YcvECxtXoxQ?star...  \n",
            "2  https://www.youtube.com/embed/YcvECxtXoxQ?star...  \n",
            "3  https://www.youtube.com/embed/YcvECxtXoxQ?star...  \n",
            "4  https://www.youtube.com/embed/YcvECxtXoxQ?star...  \n"
          ]
        }
      ],
      "source": [
        "# Step 5 & 6: Run retrieval over all Hugging Face query images\n",
        "%pip install datasets -q\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"aegean-ai/rav4-exterior-images\", split=\"train\")\n",
        "all_results = []\n",
        "\n",
        "for sample in ds:\n",
        "    image = sample[\"image\"]  # PIL Image\n",
        "    image.save(\"temp_query.jpg\")\n",
        "\n",
        "    query_classes = get_query_classes(\"temp_query.jpg\")\n",
        "    if not query_classes:\n",
        "        continue\n",
        "\n",
        "    matches = df[df[\"class_label\"].isin(query_classes)].copy()\n",
        "    matches = matches.sort_values(\"timestamp_sec\")\n",
        "    intervals = merge_intervals(matches[\"timestamp_sec\"].tolist())\n",
        "\n",
        "    for (start, end) in intervals:\n",
        "        segment_detections = matches[\n",
        "            (matches[\"timestamp_sec\"] >= start) & (matches[\"timestamp_sec\"] <= end)\n",
        "        ]\n",
        "        all_results.append({\n",
        "            \"query_timestamp\": sample[\"timestamp\"],\n",
        "            \"start_timestamp\": start,\n",
        "            \"end_timestamp\": end,\n",
        "            \"class_label\": \", \".join(query_classes),\n",
        "            \"number_of_supporting_detections\": len(segment_detections),\n",
        "            \"verify_url\": f\"https://www.youtube.com/embed/YcvECxtXoxQ?start={start}&end={end}\"\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df.to_parquet(\"retrieval_results.parquet\", index=False)\n",
        "print(f\"Total retrieval results: {len(results_df)}\")\n",
        "print(results_df.head())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2026.01"
      },
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
